<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>SHIVAKASU</title>
  <icon>https://www.gravatar.com/avatar/db3726c77acefe0355d29843a28e9ca4</icon>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://shivakasu.github.io/"/>
  <updated>2020-01-05T05:18:16.106Z</updated>
  <id>http://shivakasu.github.io/</id>
  
  <author>
    <name>w.k.x.</name>
    <email>wkx1996@foxmail.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>流畅的Python Chapter 1：Python 数据模型</title>
    <link href="http://shivakasu.github.io/2019/02/04/fpy0/"/>
    <id>http://shivakasu.github.io/2019/02/04/fpy0/</id>
    <published>2019-02-04T07:08:20.000Z</published>
    <updated>2020-01-05T05:18:16.106Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;这一章写的是python的特殊方法(special method)，又叫作魔术方法(magic method)。最常见的就是面向对象编程时的初始化方法<code>__init__</code>，这类方法的特点有：</p><ul><li>方法名首尾有两个下划线。</li><li>所有特殊方法都是python内置的，使用时只需要在类里重写，最好不要自己定义新的特殊方法。</li><li>特殊方法都与特殊操作绑定，不需要显式调用。如<code>__init__</code>与对象初始化绑定，<code>__len__</code>与<code>len()</code>方法绑定，<code>__add__</code>与<code>+</code>运算绑定。</li></ul><p>&emsp;&emsp;部分特殊方法如下，首先是与运算符无关的特殊方法：<br><a href="/2019/02/04/fpy0/fpy0-0.png" data-fancybox="group" data-caption="fpy0-0" class="fancybox"><img alt="fpy0-0" title="fpy0-0" data-src="/2019/02/04/fpy0/fpy0-0.png" class="lazyload"></a></p><p>然后是与运算符有关的特殊方法：<br><a href="/2019/02/04/fpy0/fpy0-1.png" data-fancybox="group" data-caption="fpy0-1" class="fancybox"><img alt="fpy0-1" title="fpy0-1" data-src="/2019/02/04/fpy0/fpy0-1.png" class="lazyload"></a></p><p>&emsp;&emsp;<code>__repr__</code>和<code>__str__</code>都是用于定义对象的字符串表示形式。区别是前者用于在命令行直接输入一个对象时返回的字符串，后者是调用<code>str()</code>方法或<code>print()</code>时返回的字符串。如果只想实现其中一个特殊方法，就实现<code>__repr__</code>，因为没有<code>__str__</code>时解释器会自动调用<code>__repr__</code>。</p><p>&emsp;&emsp;<code>__bool__</code>用于定义一个对象的真值，如果对象需要参与条件判定的话，可以用<code>bool()</code>方法。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;emsp;&amp;emsp;这一章写的是python的特殊方法(special method)，又叫作魔术方法(magic method)。最常见的就是面向对象编程时的初始化方法&lt;code&gt;__init__&lt;/code&gt;，这类方法的特点有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;方法名首尾
      
    
    </summary>
    
    
      <category term="读书笔记" scheme="http://shivakasu.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Python" scheme="http://shivakasu.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>现代信息检索 Chapter 3：信息检索建模</title>
    <link href="http://shivakasu.github.io/2019/01/24/mir2/"/>
    <id>http://shivakasu.github.io/2019/01/24/mir2/</id>
    <published>2019-01-24T05:40:20.000Z</published>
    <updated>2020-01-05T05:41:18.346Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-信息检索模型"><a href="#1-信息检索模型" class="headerlink" title="1 信息检索模型"></a>1 信息检索模型</h2><p>&emsp;&emsp;信息检索模型是一个四元组 <script type="math/tex">[D,Q,F,R(q_i,d_i)]</script> 。其中D(Document)是文档表示的集合，Q(Query)是查询表示的集合，F(Framework)是对文档、查询及其关系建模的框架，例如布尔框架、线性框架，R(Ranking)是排序函数，对于查询表达式 <script type="math/tex">q_i\in Q</script> 和文档表达式 <script type="math/tex">d_i\in D</script> ，函数返回文档 <script type="math/tex">d_i</script> 关于查询<script type="math/tex">q_i</script>的文档次序。</p><p>&emsp;&emsp;信息检索主要基于文本，文本模型也细分为是否考虑文本结构，所谓考虑文本结构就是区别对待标题、段落等文档不同结构处的内容。在web中，由于文档数量巨大，还需要考虑网页之间的链接，如今的web排序函数结合了经典的信息检索模型和基于链接模型的特征来提高检索性能。信息检索还可基于图像、音频等多媒体数据，检索策略更复杂。信息检索模型的分类体系见下图：<br><a href="/2019/01/24/mir2/mir2-0.png" data-fancybox="group" data-caption="mir2-0" class="fancybox"><img alt="mir2-0" title="mir2-0" data-src="/2019/01/24/mir2/mir2-0.png" class="lazyload"></a></p><h2 id="2-经典信息检索"><a href="#2-经典信息检索" class="headerlink" title="2 经典信息检索"></a>2 经典信息检索</h2><h3 id="2-1-基本概念"><a href="#2-1-基本概念" class="headerlink" title="2.1 基本概念"></a>2.1 基本概念</h3><ul><li>索引项(index term)：文档里的一个词或一组连续的词，主要是名词，因为名词相比于形容词、副词等往往能包含更多信息，具体的选择策略因人而异。</li><li>词汇表(vocabulary)： <script type="math/tex">V=(k_1,k_2,\cdots ,k_t)</script> ，其中 <script type="math/tex">t</script> 是文档集中索引项的数量， <script type="math/tex">k_i</script> 是某个索引项。</li><li>文档表示：就是简单的词袋方法，表示成和词汇表一样长的向量，其中每个元素是0或1，0表示对应的索引项在文档中未出现，1表示对应的索引项在文档中出现。</li><li>查询表示：和文档表示相同，每个元素表示相应索引项是否在查询中出现。</li><li>项-文档矩阵：行数是索引项个数，列数是文档个数，元素 <script type="math/tex">f_{i,j}</script> 表示第 <script type="math/tex">i</script> 个索引项在第 <script type="math/tex">j</script> 个文档中出现的频数。显然，在词袋方法中是0-1矩阵。</li><li>文档的逻辑视图：大概就是表示文档的方式。通常是把文档全文转变成索引项集合，流程如下图：<br><a href="/2019/01/24/mir2/mir2-1.png" data-fancybox="group" data-caption="mir2-1" class="fancybox"><img alt="mir2-1" title="mir2-1" data-src="/2019/01/24/mir2/mir2-1.png" class="lazyload"></a></li></ul><h3 id="2-2-布尔模型"><a href="#2-2-布尔模型" class="headerlink" title="2.2 布尔模型"></a>2.2 布尔模型</h3><p>&emsp;&emsp;使用词袋方法表示文档，用析取范式(disjunct normal form)表示查询。例如对于词汇表 <script type="math/tex">V=(k_a,k_b,k_c,k_d)</script> 和查询 <script type="math/tex">q=k_a\wedge (k_b\vee k_c)</script> ，用析取范式表示查询为：</p><script type="math/tex; mode=display">q_{DNF}=(1,1,1,0)\vee(1,1,1,1)\vee(1,1,0,0)\vee(1,1,0,1)\vee(1,0,0,0)\vee(1,0,0,1)</script><p>文档与查询的相关度定义为析取范式中是否有一项与文档表示相同，因此也是二值的。</p><p>&emsp;&emsp;布尔模型的优点是简单，缺点是不支持排序。因为相关度是二值的，只能表示相关与否，而不能表示相关的程度。</p><h3 id="2-3-项权重"><a href="#2-3-项权重" class="headerlink" title="2.3 项权重"></a>2.3 项权重</h3><p>&emsp;&emsp;提高检索质量的一个方法是给每个索引项设置权重，通常根据索引项在整个文档集中出现的频次设置权重。如果不假设索引项之间相互独立，还要考虑索引项之间的相关性，因为索引项之间的关联往往会反映文档之间的关联，一种计算项间相关性的方法是项-文档矩阵乘他的转置矩阵，如下图：<br><a href="/2019/01/24/mir2/mir2-2.png" data-fancybox="group" data-caption="mir2-2" class="fancybox"><img alt="mir2-2" title="mir2-2" data-src="/2019/01/24/mir2/mir2-2.png" class="lazyload"></a><br>假设项间相互独立可以简化模型、提高计算效率，而利用项间相关性提高排序水平也是十分复杂的工作，考虑了项间相关性并不能保证排序水平的提高，因此是否假设项间相互独立没有固定的标准。</p><h3 id="2-4-TD-IDF"><a href="#2-4-TD-IDF" class="headerlink" title="2.4 TD-IDF"></a>2.4 TD-IDF</h3><p>&emsp;&emsp;TF-IDF是一个常用的计算项权重的指标，其中TF(Term frequency)表示项频，IDF(Inverse document frequency)表示反比文档频率。</p><p>&emsp;&emsp;使用项频是基于Luhn假设，即高频项对描述文档的关键主题是重要的。可以直接将索引项的频次作为TF权重，即 <script type="math/tex">tf_{i,j}=f_{i,j}</script> ，但考虑到要与IDF权重结合，而IDF使用了对数运算，因此通常使用TF权重的一个变种：</p><script type="math/tex; mode=display">tf_{i,j}=\begin{cases}1+log_2f_{i,j} & f_{i,j}>0 \\0 & otherwise\end{cases}</script><p>&emsp;&emsp;TF权重倾向于给频次高的索引项更大的权重，但也要考虑索引项的区分度，即索引项特异性(term specificity)。如果一个索引项在每个文档中都出现，虽然出现频次高，但是对于文档排序等任务没有太大帮助，最常见的就是a、the这样的冠词、连词和介词。因此不仅要考虑高频项，还要考虑区分度大的索引项。IDF权重考虑的就是某个索引项在多少个文档中出现，即相对文档频率 <script type="math/tex">n_i/N</script> ， <script type="math/tex">IDF_i=log_2\frac{N}{n_i}</script> ，其中 <script type="math/tex">N</script> 是文档集中的文档数量， <script type="math/tex">n_i</script> 是出现索引项 <script type="math/tex">k_i</script> 的文档数量，因为相对文档频率越小的索引项区分度越大，所以IDF使用了相对文档频率的倒数，称作反比文档频率。</p><p>&emsp;&emsp;TF-IDF将二者结合起来，计算方法如下：</p><script type="math/tex; mode=display">w_{i,j}=\begin{cases}(1+log_2f_{i,j})*log_2\frac{N}{n_i} & f_{i,j}>0 \\0 & otherwise\end{cases}</script><p>&emsp;&emsp;TF、IDF和TF-IDF有多种变体。TF变体如下：<br><a href="/2019/01/24/mir2/mir2-3.png" data-fancybox="group" data-caption="mir2-3" class="fancybox"><img alt="mir2-3" title="mir2-3" data-src="/2019/01/24/mir2/mir2-3.png" class="lazyload"></a></p><p>IDF变体如下：<br><a href="/2019/01/24/mir2/mir2-4.png" data-fancybox="group" data-caption="mir2-4" class="fancybox"><img alt="mir2-4" title="mir2-4" data-src="/2019/01/24/mir2/mir2-4.png" class="lazyload"></a></p><p>TF-IDF变体如下：<br><a href="/2019/01/24/mir2/mir2-5.png" data-fancybox="group" data-caption="mir2-5" class="fancybox"><img alt="mir2-5" title="mir2-5" data-src="/2019/01/24/mir2/mir2-5.png" class="lazyload"></a></p><p>&emsp;&emsp;通过下图可以分析出TF-IDF的性质。TF和IDF权重表现出的幂律特性会相互平衡，高TF权重趋于和低IDF权重结合，低TF权重趋于和高IDF权重结合，结果是TF-IDF权重最高的索引项往往具有中等TF和IDF权重，而项频太高的项和文档频率太低的项经过平衡后都具有较低的TF-IDF权重。妙啊！<br><a href="/2019/01/24/mir2/mir2-6.png" data-fancybox="group" data-caption="mir2-6" class="fancybox"><img alt="mir2-6" title="mir2-6" data-src="/2019/01/24/mir2/mir2-6.png" class="lazyload"></a></p><h3 id="2-5-文档长度归一化"><a href="#2-5-文档长度归一化" class="headerlink" title="2.5 文档长度归一化"></a>2.5 文档长度归一化</h3><p>&emsp;&emsp;对于给定的查询，较长的文档仅仅因为包含更多的索引项而更可能被检出，为了消除这一影响，可以把文档的排序除以其长度，这个过程称为文档长度归一化，如何计算文档长度取决于文档的表示形式。</p><h3 id="2-6-向量模型"><a href="#2-6-向量模型" class="headerlink" title="2.6 向量模型"></a>2.6 向量模型</h3><p>&emsp;&emsp;布尔模型使用析取范式的每一项和文档表示进行严格匹配，难以得到理想的结果。向量模型将文档和查询表示为向量形式，使用向量夹角的余弦值衡量相似度，成功将相似度量化为可用于比较和排序的数值，基于相似度的排序可以理解为一种部分匹配策略。文档的向量表示为 <script type="math/tex">\vec{d_j}=(w_{1,j},w_{2,j},\cdots,w_{t,j})</script> ，其中 <script type="math/tex">t</script> 是索引项总个数， <script type="math/tex">w_{i,j}</script>是项-文档对 <script type="math/tex">(k_i,d_j)</script> 的权重，一般采用TF-IDF权重，查询的向量表示为 <script type="math/tex">\vec{q}=(w_{1,q},w_{2,q},\cdots,w_{t,q})</script> , <script type="math/tex">w_{i,q}</script>是项-查询对 <script type="math/tex">(k_i,q)</script> 的权重。文档-查询余弦相似度公式为：</p><script type="math/tex; mode=display">sim(d_j,q)=\frac{\vec{d_j}\cdot\vec{q}}{|\vec{d_j}|\times|\vec{q}|}</script><p>注意到余弦公式分母的向量范数恰好也起到了文档长度归一化的作用。</p><h3 id="2-7-概率模型"><a href="#2-7-概率模型" class="headerlink" title="2.7 概率模型"></a>2.7 概率模型</h3><p>&emsp;&emsp;概率模型的目标是估计文档与查询相关的概率，他假定这种相关性仅依赖于文档和查询本身的表示，并假定存在一个理想答案集，仅包含所有与查询相关的文档，因此能够最大化与用户相关的总体概率。显然，这种假设是对真实情况的简化，所以必然会存在一些缺陷。</p><p>&emsp;&emsp;概率模型计算相关度的公式是：</p><script type="math/tex; mode=display">sim(d_j,q)=\frac{P(R|\vec{d_j})}{P(\overline{R}|\vec{d_j})}</script><p>其中 <script type="math/tex">R</script> 是与查询 <script type="math/tex">q</script> 相关的文档的集合， <script type="math/tex">\overline{R}</script> 是与查询 <script type="math/tex">q</script> 不相关的文档的集合， <script type="math/tex">P(R|\vec{d_j})</script>是文档 <script type="math/tex">d_j</script> 与查询 <script type="math/tex">q</script> 相关的概率， <script type="math/tex">P(\overline{R}|\vec{d_j})</script>是文档 <script type="math/tex">d_j</script> 与查询 <script type="math/tex">q</script> 不相关的概率。根据贝叶斯公式：</p><script type="math/tex; mode=display">sim(d_j,q)=\frac{P(\vec{d_j}|R,q)\times P(R,q)}{P(\vec{d_j}|\overline{R},q)\times P(\overline{R},q)}\sim\frac{P(\vec{d_j}|R,q)}{P(\vec{d_j}|\overline{R},q)}</script><p>其中 <script type="math/tex">P(\vec{d_j}|R,q)</script> 表示从查询 <script type="math/tex">q</script> 的相关文档集 <script type="math/tex">R</script> 中随机选择的一偏文档表示为 <script type="math/tex">\vec{d_j}</script> 的概率， <script type="math/tex">P(R,q)</script> 表示从整个文档集中随机选择的文档和查询 <script type="math/tex">q</script> 相关的概率， <script type="math/tex">P(\vec{d_j}|\overline{R},q)</script> 和 <script type="math/tex">P(\overline{R},q)</script> 的含义是相似且互补的。概率模型中不考虑项权重，所以 <script type="math/tex">\vec{d_j}</script> 是一个二值向量，如果假设索引项间的独立性，即所谓的二值独立假设，可以得到：</p><script type="math/tex; mode=display">sim(d_j,q)\sim\frac{(\prod_{k_i|w_{i,j}=1}p_{iR})\times(\prod_{k_i|w_{i,j}=0}(1-p_{iR}))}{(\prod_{k_i|w_{i,j}=1}q_{iR})\times(\prod_{k_i|w_{i,j}=0}(1-q_{iR}))}</script><p>其中 <script type="math/tex">p_{iR}</script> 表示索引项 <script type="math/tex">k_i</script> 出现在从查询 <script type="math/tex">q</script> 的相关文档集 <script type="math/tex">R</script> 中随机选择的一偏文档内的概率， <script type="math/tex">q_{iR}</script> 表示索引项 <script type="math/tex">k_i</script> 出现在从查询 <script type="math/tex">q</script> 的不相关文档集 <script type="math/tex">\overline{R}</script> 中随机选择的一偏文档内的概率。使用对数函数只改变数值而不改变排序结果，所以可以进一步简化为：</p><script type="math/tex; mode=display">sim(d_j,q)\sim\sum_{k_i\in q\wedge k_i\in d_j}log(\frac{p_{iR}}{1-p_{iR}})+log(\frac{1-q_{iR}}{q_{iR}})</script><p>得到了相似度公式，接下来就是如何计算 <script type="math/tex">p_{iR}</script> 和 <script type="math/tex">q_{iR}</script> 。</p><p>&emsp;&emsp;一种计算方法是使用索引项出现列联表，如下：</p><div class="table-container"><table><thead><tr><th style="text-align:center">情况</th><th style="text-align:center">相关文档数</th><th style="text-align:center">不相关文档数</th><th style="text-align:center">总文档数</th></tr></thead><tbody><tr><td style="text-align:center">包含 $k_i$ 的文档</td><td style="text-align:center">$r_i$</td><td style="text-align:center">$n_i-r_i$</td><td style="text-align:center">$n_i$</td></tr><tr><td style="text-align:center">不包含 $k_i$ 的文档</td><td style="text-align:center">$R-r_i$</td><td style="text-align:center">$N-n_i-(R-r_i)$</td><td style="text-align:center">$N-n_i$</td></tr><tr><td style="text-align:center">所有文档</td><td style="text-align:center">$R$</td><td style="text-align:center">$N-R$</td><td style="text-align:center">$N$</td></tr></tbody></table></div><p>那么可以得到，</p><script type="math/tex; mode=display">p_{iR}=\frac{r_i}{R}\quad, \quad q_{iR}=\frac{n_i-r_i}{N-R}</script><script type="math/tex; mode=display">sim(d_j,q)\sim\sum_{k_i\in q\wedge k_i\in d_j}log(\frac{(r_i+0.5)(N-n_i-R+r_i+0.5)}{(R-r_i+0.5)(n_i-r_i+0.5)})</script><p>之所以给每个包含 <script type="math/tex">r_i</script> 的项加0.5，是为了减小极端情况下过小的 <script type="math/tex">r_i</script> 对 <script type="math/tex">log</script> 计算的影响。这种方法需要人工估计 <script type="math/tex">r_i</script> 和 <script type="math/tex">R</script> 值，所以不实用，同时缺少文档长度归一化的操作，使得排序效果也不是很好。</p><p>&emsp;&emsp;另一种方法是在避免人工估计的条件下，基于几条假设来自动更新 <script type="math/tex">r_i</script> 和 <script type="math/tex">R</script> 值，个人认为这里的假设太牵强，理解不了。</p><p>&emsp;&emsp;概率模型的优点是能按照相关概率进行排序，但其认为相关性仅与文档和查询的内容有关，所以实际应用时效果难以保证。此外，概率模型不可避免地要做初始估计将文档分为相关和不相关集合，不太好操作。观察上面计算 <script type="math/tex">sim(d_j,q)</script> 的公式，与IDF权重的公式是相似的，从这个角度看，概率模型的另一个缺点是没有用到TF特征，也没有进行文档长度归一化。</p><h2 id="3-其他集合论模型"><a href="#3-其他集合论模型" class="headerlink" title="3 其他集合论模型"></a>3 其他集合论模型</h2><h3 id="3-1-基于集合的模型"><a href="#3-1-基于集合的模型" class="headerlink" title="3.1 基于集合的模型"></a>3.1 基于集合的模型</h3><p>&emsp;&emsp;基于集合的模型不考虑单独的索引项，而是考虑索引项之间的相互依赖性，通过引入项集的概念表示索引项之间的关联。</p><p>&emsp;&emsp;项集(Termset)：项集 <script type="math/tex">S_i=\{k_a,k_b,\cdots,k_n\}</script> 是文档集中索引项的子集。若 <script type="math/tex">S_i</script> 中所有的索引项都出现在文档 <script type="math/tex">d_j</script> 中，就称项集 <script type="math/tex">S_i</script> 出现在 <script type="math/tex">d_j</script> 中。</p><p>&emsp;&emsp;显然，若文档集中有 <script type="math/tex">t</script> 个索引项，则理论上有 <script type="math/tex">2^t</script> 个项集，但实际数据集中一般仅包含部分项集。同时，用项集表示替代索引项表示就需要把项的词汇表改为项集的词汇表，即 <script type="math/tex">V_S=\{S_1,S_2,\cdots,S_{2^t}\}</script> 。</p><p>&emsp;&emsp;频繁项集(Frequent termsets)：由 <script type="math/tex">n</script> 个项构成的项集称为 <script type="math/tex">n</script> 项集，如果包含某个 <script type="math/tex">n</script> 项集的文档数 <script type="math/tex">\mathcal{N}_i</script> 高于某个给定的阈值，那么这个 <script type="math/tex">n</script> 项集 <script type="math/tex">S_i</script> 称为是频繁的。显然，一个 <script type="math/tex">n</script> 项集是频繁的当且仅当他的所有 <script type="math/tex">(n-1)</script> 项集都是频繁地。</p><p>&emsp;&emsp;在TF-IDF中，计算的权重是项-文档矩阵的元素，在集合模型中与之类似，计算的权重是项集-文档矩阵的元素。对于 <script type="math/tex">(S_i,d_j)</script> ，令 <script type="math/tex">N</script> 是文档集中文档总数，<script type="math/tex">\mathcal{F}_{i,j}</script> 是项集 <script type="math/tex">S_i</script> 在文档 <script type="math/tex">d_j</script> 中的原始出现频率，赋予项集权重：</p><script type="math/tex; mode=display">\mathcal{W}_{i,j}=\begin{cases}(1+log_2\mathcal{F}_{i,j})*log_2(1+\frac{N}{\mathcal{N}_i}) & \mathcal{F}_{i,j}>0 \\0 & otherwise\end{cases}</script><p>同理， <script type="math/tex">\vec{d_j}=(\mathcal{W}_{1,j},\mathcal{W}_{2,j},\cdots,\mathcal{W}_{2^t,j})</script> ， <script type="math/tex">\vec{q}=(\mathcal{W}_{1,q},\mathcal{W}_{2,q},\cdots,\mathcal{W}_{2^t,q})</script>，相似度计算公式为：</p><script type="math/tex; mode=display">sim(d_j,q)=\frac{\vec{d_j}\cdot\vec{q}}{|\vec{d_j}|\times|\vec{q}|}=\frac{\sum_{S_i}\mathcal{W}_{i,j}\times\mathcal{W}_{i,q}}{|\vec{d_j}|\times|\vec{q}|}</script><p>由于项集空间是项空间的指数级大小，所以相似度的计算十分复杂，需要进行计算简化。例如在计算向量范数时只考虑 <script type="math/tex">1</script> 项集。或是进一步缩小项集的范围，只考虑频繁闭项集，闭项集(Closed termset)就是项集的闭包，比如项集 <script type="math/tex">\{k_1\}</script> 、 <script type="math/tex">\{k_2\}</script> 、 <script type="math/tex">\{k_1,k_2\}</script>出现在相同的文档子集中，那么可以只计算 <script type="math/tex">\{k_1,k_2\}</script>，大大减小了计算量，除了频繁闭项集，还可选择最大频繁集，即添加任何索引项都不能使其保持频繁性。从项集数目上看，频繁项集&gt;频繁闭项集&gt;最大频繁集，需要注意的是，减少计算必然伴随着信息的损失，因此需要根据实际情况进行权衡。</p><h3 id="3-2-扩展布尔模型"><a href="#3-2-扩展布尔模型" class="headerlink" title="3.2 扩展布尔模型"></a>3.2 扩展布尔模型</h3><p>&emsp;&emsp;用向量模型的特征扩展布尔模型，狗尾续貂？</p><h3 id="3-3-模糊集模型"><a href="#3-3-模糊集模型" class="headerlink" title="3.3 模糊集模型"></a>3.3 模糊集模型</h3><p>&emsp;&emsp;模糊集模型基于模糊集理论，对于每一个索引项 <script type="math/tex">k_i</script> ，为其分配一个模糊集(fuzzy set) <script type="math/tex">D_i</script> ，模糊集为每一个文档 <script type="math/tex">d_j</script> 分配一个介于区间 <script type="math/tex">[0,1]</script> 之间的隶属度(degree of membership)  <script type="math/tex">\mu_{i,j}</script> ，若 <script type="math/tex">\mu_{i,j}\sim 1</script> 表明 <script type="math/tex">k_i</script> 是 <script type="math/tex">d_j</script> 的良好模糊索引项，若 <script type="math/tex">\mu_{i,j}\sim 0</script> 表明 <script type="math/tex">k_i</script> 不是 <script type="math/tex">d_j</script> 的良好模糊索引项。隶属度可以通过项间相关性矩阵 <script type="math/tex">C</script> 来计算，索引项 <script type="math/tex">k_i</script> 和 <script type="math/tex">k_l</script> 的相关性计算公式为：</p><script type="math/tex; mode=display">c_{i,l}=\frac{n_{i,l}}{n_i+n_l-n_{i,l}}</script><p>其中 <script type="math/tex">n_i</script> 是含有索引项 <script type="math/tex">k_i</script> 的文档数， <script type="math/tex">n_l</script> 是含有索引项 <script type="math/tex">k_l</script> 的文档数， <script type="math/tex">n_{i,l}</script> 是同时含有这两个索引项的文档数，这种相关性度量被广泛应用在聚类算法中。有了相关性度量，就可以计算隶属度：</p><script type="math/tex; mode=display">\mu_{i,j}=1-\prod_{k_l\in d_j}(1-c_{i,l})</script><p>这其实就是在考虑 <script type="math/tex">k_i</script> 和 <script type="math/tex">d_j</script> 中每一个索引项的相关性，可以看出，只要 <script type="math/tex">d_j</script> 中至少有一个索引项 <script type="math/tex">k_l</script> 与 <script type="math/tex">k_i</script> 关系密切(即 <script type="math/tex">c_{i,l}\sim 1</script> )，则 <script type="math/tex">\mu_{i,j}\sim 1</script> 。此外，采用代数和的方式计算而不是对所有相关性使用 <script type="math/tex">max</script> 函数，可以使 <script type="math/tex">\mu_{i,j}</script> 的值变得平滑。</p><p>&emsp;&emsp;有了文档相对索引项的隶属度，就可以进一步计算文档相对于查询的隶属度，因为借鉴布尔模型的方法，查询可以表示成索引项组成的逻辑表达式。例如对于查询 <script type="math/tex">q=k_a\wedge (k_b\vee\neg k_c)</script> ，可以写成析取范式 <script type="math/tex">\vec{q}_{dnf}=(1,1,1)\vee(1,1,0)\vee(1,0,0)</script> ，设 <script type="math/tex">D_a</script> 、 <script type="math/tex">D_b</script> 、 <script type="math/tex">D_c</script> 分别是 <script type="math/tex">k_a</script> 、 <script type="math/tex">k_b</script> 、 <script type="math/tex">k_c</script> 的模糊集，查询的模糊集 <script type="math/tex">D_q</script> 可以从下图理解：<br><a href="/2019/01/24/mir2/mir2-7.png" data-fancybox="group" data-caption="mir2-7" class="fancybox"><img alt="mir2-7" title="mir2-7" data-src="/2019/01/24/mir2/mir2-7.png" class="lazyload"></a><br>其中， <script type="math/tex">cc_1=\mu_{a,j}\mu_{b,j}\mu_{c,j}</script> 、 <script type="math/tex">cc_2=\mu_{a,j}\mu_{b,j}(1-\mu_{c,j})</script> 、 <script type="math/tex">cc_3=\mu_{a,j}(1-\mu_{b,j})(1-\mu_{c,j})</script> ，则：</p><script type="math/tex; mode=display">\mu_{q,j}=1-\prod_{i=1}^3(1-cc_i)</script><p>同样，采用代数和的方式计算而不是对所有相关性使用 <script type="math/tex">max</script> 函数，可以使<script type="math/tex">\mu_{q,j}</script> 的值变得平滑。</p><h2 id="4-其他代数模型"><a href="#4-其他代数模型" class="headerlink" title="4 其他代数模型"></a>4 其他代数模型</h2><h3 id="4-1-广义向量空间模型"><a href="#4-1-广义向量空间模型" class="headerlink" title="4.1 广义向量空间模型"></a>4.1 广义向量空间模型</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-信息检索模型&quot;&gt;&lt;a href=&quot;#1-信息检索模型&quot; class=&quot;headerlink&quot; title=&quot;1 信息检索模型&quot;&gt;&lt;/a&gt;1 信息检索模型&lt;/h2&gt;&lt;p&gt;&amp;emsp;&amp;emsp;信息检索模型是一个四元组 &lt;script type=&quot;math/te
      
    
    </summary>
    
    
      <category term="读书笔记" scheme="http://shivakasu.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="计算机理论" scheme="http://shivakasu.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%90%86%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>现代信息检索 Chapter 2：用户搜索界面</title>
    <link href="http://shivakasu.github.io/2019/01/19/mir1/"/>
    <id>http://shivakasu.github.io/2019/01/19/mir1/</id>
    <published>2019-01-19T09:26:20.000Z</published>
    <updated>2020-01-05T05:00:41.633Z</updated>
    
    <content type="html"><![CDATA[<h3 id="人们如何搜索"><a href="#人们如何搜索" class="headerlink" title="人们如何搜索"></a>人们如何搜索</h3><ul><li><p>信息查找(information lookup)类似于事实检索或问题回答，只需要简短而离散的信息。</p></li><li><p>探索式搜索(exploratory search)分为学习和调查两类，需要花费更长的时间并整合更多内容。</p></li><li><p>信息搜寻过程是由一系列相互关联但又不完全相同的搜索所组成的，搜索带来的主要价值体现在搜索过程中持续的学习和所获得的信息，而不只是最后的搜索结果。</p></li><li><p>信息搜寻过程的经典模型：明确问题-&gt;表达信息需求-&gt;构造查询-&gt;评价结果。经典模型假设用户的信息需求是静态的，最近的模型强调搜索过程的动态性，认为用户会根据搜索结果动态调整信息需求，这种动态过程有时称为搜索的采摘模型(berry picking model)。例如，用户给出一个快速、不精确的查询，近似得到信息空间的一部分内容，再进行一系列本地导航操作，从而获得更贴近用户兴趣的信息。有些搜索模型关注搜索策略，对搜索策略建模，预测用户的搜索行为。</p></li><li><p>除了传统的搜索框查询，还可以使用导航界面，让用户通过浏览导航和点击链接搜寻信息。</p></li></ul><h3 id="现今的搜索界面"><a href="#现今的搜索界面" class="headerlink" title="现今的搜索界面"></a>现今的搜索界面</h3><ul><li><p>启动搜寻：通常使用Web搜索引擎。导航网站逐渐被淘汰，一是因为网络规模变大，无法手动构造目录，二是因为Web搜索的精度提高。</p></li><li><p>查询描述：解析查询项，Web排序</p></li><li><p>查询描述界面：搜索框placeholder提示，自动补全建议列表。根据用户搜索历史或其他用户的热门搜索。</p></li><li><p>检索结果显示：文档摘要，查询项高亮。</p></li><li><p>查询重构：拼写校对或建议，相关查询项推荐。</p></li><li><p>组织搜索结果：分类和聚类。区别在于是否需要人工组织层次结构。</p></li></ul><p>(这章真的是看不下去了，一个搜索界面说了这么多废话，太无聊了)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;人们如何搜索&quot;&gt;&lt;a href=&quot;#人们如何搜索&quot; class=&quot;headerlink&quot; title=&quot;人们如何搜索&quot;&gt;&lt;/a&gt;人们如何搜索&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;信息查找(information lookup)类似于事实检索或问题回答，只需要简短而离散
      
    
    </summary>
    
    
      <category term="读书笔记" scheme="http://shivakasu.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="计算机理论" scheme="http://shivakasu.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%90%86%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>现代信息检索 Chapter 1：引言</title>
    <link href="http://shivakasu.github.io/2019/01/18/mir0/"/>
    <id>http://shivakasu.github.io/2019/01/18/mir0/</id>
    <published>2019-01-18T08:36:26.000Z</published>
    <updated>2020-01-05T04:57:35.380Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>信息检索涉及对文档、网页、联机目录、结构化和半结构化记录及多媒体对象等信息项的表示、存储、组织和访问。信息项的表示和组织必须便于用户访问他们感兴趣的信息。</p></li><li><p>信息检索发展的关键阶段：书籍-&gt;图书馆-&gt;索引-&gt;计算机-&gt;排序技术和搜索引擎等现代研究内容</p></li><li><p>信息检索系统的主要目标是检出所有和用户查询相关的文档，并且把检出的不相关文档控制在最低限度。相关性的概念对信息检索至关重要。对相关性的评估没有固定标准，不存在能在任何时间给任何用户提供完美答案的检索系统。</p></li><li><p>检索任务可分为浏览和搜索，浏览是探索式检索，目标不太明确，搜索则相反。</p></li><li><p>信息检索系统的高层软件架构：<br><a href="/2019/01/18/mir0/mir0-0.png" data-fancybox="group" data-caption="mir0-0" class="fancybox"><img alt="mir0-0" title="mir0-0" data-src="/2019/01/18/mir0/mir0-0.png" class="lazyload"></a></p></li><li><p>文档的索引、检索和排序过程：<br><a href="/2019/01/18/mir0/mir0-1.png" data-fancybox="group" data-caption="mir0-1" class="fancybox"><img alt="mir0-1" title="mir0-1" data-src="/2019/01/18/mir0/mir0-1.png" class="lazyload"></a></p></li><li><p>Web流行的根源：出版自由。</p></li><li><p>Web对搜索的影响：网页爬取新技术，海量文档集和海量查询流量，相关性预测更复杂，从文字搜索转向结构化数据搜索，垃圾信息泛滥。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;p&gt;信息检索涉及对文档、网页、联机目录、结构化和半结构化记录及多媒体对象等信息项的表示、存储、组织和访问。信息项的表示和组织必须便于用户访问他们感兴趣的信息。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;信息检索发展的关键阶段：书籍-&amp;gt;图书馆-&amp;gt;索引-&amp;gt
      
    
    </summary>
    
    
      <category term="读书笔记" scheme="http://shivakasu.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="计算机理论" scheme="http://shivakasu.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%90%86%E8%AE%BA/"/>
    
  </entry>
  
</feed>
